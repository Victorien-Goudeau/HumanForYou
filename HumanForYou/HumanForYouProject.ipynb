{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:00:25.722053300Z",
     "start_time": "2024-02-08T10:00:24.139882700Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os, uuid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from io import BytesIO\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "warnings.filterwarnings('ignore')\n",
    "from pycaret.classification import *\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "connect_str = os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "container_client = blob_service_client.get_container_client(\"data\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:00:25.723170800Z",
     "start_time": "2024-02-08T10:00:25.722053300Z"
    }
   },
   "id": "f7e67276eeeffbb2",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def download_blob_to_df(blob_name):\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    download_stream = blob_client.download_blob()\n",
    "    blob_data = BytesIO(download_stream.readall())\n",
    "    return pd.read_csv(blob_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:00:25.734584200Z",
     "start_time": "2024-02-08T10:00:25.725577Z"
    }
   },
   "id": "e2bd030194ced972",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "in_time_df = download_blob_to_df(\"in_time.csv\")\n",
    "manager_survey_data_df = download_blob_to_df(\"manager_survey_data.csv\")\n",
    "employee_survey_data_df = download_blob_to_df(\"employee_survey_data.csv\")\n",
    "out_time_df = download_blob_to_df(\"out_time.csv\")\n",
    "general_data_df = download_blob_to_df(\"general_data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:00:31.501582600Z",
     "start_time": "2024-02-08T10:00:25.728584500Z"
    }
   },
   "id": "f9c7df4c97867cae",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class mergeDataFrame (BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, employee_survey_data_df, manager_survey_data_df, in_time_df, out_time_df):\n",
    "        self.employee_survey_data_df = employee_survey_data_df\n",
    "        self.manager_survey_data_df = manager_survey_data_df\n",
    "        self.in_time_df = in_time_df\n",
    "        self.out_time_df = out_time_df\n",
    "        \n",
    "            \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.join(self.employee_survey_data_df.set_index('EmployeeID'), on='EmployeeID')\n",
    "        X = X.join(self.manager_survey_data_df.set_index('EmployeeID'), on='EmployeeID')\n",
    "\n",
    "        employee_id_index = self.in_time_df['Unnamed: 0']\n",
    "        self.in_time_df.fillna(0,inplace=True)\n",
    "        self.out_time_df.fillna(0,inplace= True)\n",
    "        self.in_time_df.drop(columns={'Unnamed: 0':'EmployeeID'}, inplace=True)\n",
    "        self.out_time_df.drop(columns={'Unnamed: 0':'EmployeeID'}, inplace=True)\n",
    "        \n",
    "\n",
    "        for col in self.in_time_df.columns:\n",
    "            self.in_time_df[col] = pd.to_datetime(self.in_time_df[col], errors='coerce')\n",
    "\n",
    "        for col in self.out_time_df.columns:\n",
    "            self.out_time_df[col] = pd.to_datetime(self.out_time_df[col], errors='coerce')\n",
    "        \n",
    "        daily_hours = (self.out_time_df - self.in_time_df).applymap(lambda x: x.total_seconds() / 3600)\n",
    "        daily_hours = daily_hours.fillna(0)\n",
    "        daily_hours['PresenceIndicator'] = daily_hours.iloc[:, 1:].apply(lambda row: sum(1 if hours >= 8 else 0 for hours in row), axis=1)\n",
    "\n",
    "        presence_indicator = pd.DataFrame({'EmployeeID': employee_id_index, 'PresenceIndicator': daily_hours['PresenceIndicator']})\n",
    "        \n",
    "        X = X.join(presence_indicator.set_index('EmployeeID'), on='EmployeeID', how='inner')\n",
    "        return X\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:00:31.512112300Z",
     "start_time": "2024-02-08T10:00:31.505560900Z"
    }
   },
   "id": "6db6186ac9ab9cfb",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class deleteColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X.drop(columns=self.array, inplace=True)\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:00:31.522887400Z",
     "start_time": "2024-02-08T10:00:31.509562500Z"
    }
   },
   "id": "4d3bd59a918a7002",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class encodingData (BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[\"Attrition\"] = X[\"Attrition\"].map({\"Yes\": 1, \"No\": 0})\n",
    "        X[\"BusinessTravel\"] = X[\"BusinessTravel\"].map({\"Non-Travel\": 0, \"Travel_Rarely\": 1, \"Travel_Frequently\": 2})\n",
    "        ordinal_encoder = OrdinalEncoder()\n",
    "        for i in X.select_dtypes(include=[\"object\"]).keys():\n",
    "            X[i] = ordinal_encoder.fit_transform(X[[i]])\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:00:31.523886600Z",
     "start_time": "2024-02-08T10:00:31.516022600Z"
    }
   },
   "id": "f4dd920acb3686b1",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class cleanData (BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        environmentSatisfactionMedian = X.EnvironmentSatisfaction.median()\n",
    "        jobSatisfactionMedian = X.JobSatisfaction.median()\n",
    "        workLifeBalanceMedian = X.WorkLifeBalance.median()\n",
    "        totalWorkingYears_median = X['TotalWorkingYears'].median()\n",
    "        X['EnvironmentSatisfaction'].fillna(environmentSatisfactionMedian, inplace = True)\n",
    "        X['JobSatisfaction'].fillna(jobSatisfactionMedian, inplace = True)\n",
    "        X['WorkLifeBalance'].fillna(workLifeBalanceMedian, inplace = True)\n",
    "        X['TotalWorkingYears'].fillna(totalWorkingYears_median, inplace = True)\n",
    "        X['NumCompaniesWorked'].fillna(1.0, inplace = True)\n",
    "        X = X.fillna(0)\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:00:31.539460300Z",
     "start_time": "2024-02-08T10:00:31.519142Z"
    }
   },
   "id": "ca7f8dc86b8f26e9",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class corrData(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Calculate correlations and retain only significant ones\n",
    "        corr_x = self.retain_terminal(X.corr())\n",
    "        significant_parameters, _ = self.separation_significant_parameters(corr_x)\n",
    "\n",
    "        # Recalculate correlations only among significant parameters\n",
    "        corr_tmp = X[significant_parameters].corr()\n",
    "        corr_tmp = self.retain_terminal(corr_tmp)\n",
    "\n",
    "        # Select only features with non-zero correlation to 'Attrition'\n",
    "        significant_features = corr_tmp.Attrition[corr_tmp.Attrition != 0].index.tolist()\n",
    "        return X[significant_features]\n",
    "\n",
    "    def retain_terminal(self, frame):\n",
    "        # Set correlation values below threshold to zero\n",
    "        for i in frame.columns:\n",
    "            for j in frame.index:\n",
    "                if abs(frame.loc[j, i]) < 0.1:\n",
    "                    frame.loc[j, i] = 0\n",
    "        return frame\n",
    "\n",
    "    def separation_significant_parameters(self, frame):\n",
    "        # Separate parameters based on their significance\n",
    "        significant_parameter = []\n",
    "        insignificant_parameter = []\n",
    "        for column in frame.columns:\n",
    "            if not all(frame[column] == 0):\n",
    "                significant_parameter.append(column)\n",
    "            else:\n",
    "                insignificant_parameter.append(column)\n",
    "        return significant_parameter, insignificant_parameter\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:00:31.541459900Z",
     "start_time": "2024-02-08T10:00:31.525886Z"
    }
   },
   "id": "ead76ab869d4b8df",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('merge',\n                 mergeDataFrame(employee_survey_data_df=      EmployeeID  EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance\n0              1                      3.0              4.0              2.0\n1              2                      3.0              2.0              4.0\n2              3                      2.0              2.0              1.0\n3              4                      4.0              4.0              3.0\n4              5                      4.0              1.0              3.0\n...          ...                      ...              ...              ...\n4405        4406                      4.0              1.0              3.0\n4406        4407                      4.0              4.0              3.0\n4407        4408                      1.0              3.0              3.0\n4408        4409                      4.0              1.0              3.0\n4409        4410                      1.0              3.0              NaN\n\n[4410 rows x 4 columns],\n                                in_time_df=      Unnamed: 0  2015-01-01           2015-01-02           2015-01-...\n3     2015-12-31 17:09:14  \n4     2015-12-31 17:42:14  \n...                   ...  \n4405  2015-12-31 18:30:41  \n4406  2015-12-31 16:18:39  \n4407  2015-12-31 18:08:55  \n4408  2015-12-31 19:33:45  \n4409  2015-12-31 16:39:18  \n\n[4410 rows x 262 columns])),\n                ('delete',\n                 deleteColumns(array=['EmployeeID', 'EmployeeCount', 'Over18',\n                                      'StandardHours', 'MaritalStatus',\n                                      'Gender', 'Age'])),\n                ('encoding', encodingData()), ('clean', cleanData()),\n                ('corr', corrData())])",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;merge&#x27;,\n                 mergeDataFrame(employee_survey_data_df=      EmployeeID  EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance\n0              1                      3.0              4.0              2.0\n1              2                      3.0              2.0              4.0\n2              3                      2.0              2.0              1.0\n3              4                      4.0              4.0              3.0\n4              5                      4.0              1.0              3.0\n...          ...                      ...              ...              ...\n4405        4406                      4.0              1.0              3.0\n4406        4407                      4.0              4.0              3.0\n4407        4408                      1.0              3.0              3.0\n4408        4409                      4.0              1.0              3.0\n4409        4410                      1.0              3.0              NaN\n\n[4410 rows x 4 columns],\n                                in_time_df=      Unnamed: 0  2015-01-01           2015-01-02           2015-01-...\n3     2015-12-31 17:09:14  \n4     2015-12-31 17:42:14  \n...                   ...  \n4405  2015-12-31 18:30:41  \n4406  2015-12-31 16:18:39  \n4407  2015-12-31 18:08:55  \n4408  2015-12-31 19:33:45  \n4409  2015-12-31 16:39:18  \n\n[4410 rows x 262 columns])),\n                (&#x27;delete&#x27;,\n                 deleteColumns(array=[&#x27;EmployeeID&#x27;, &#x27;EmployeeCount&#x27;, &#x27;Over18&#x27;,\n                                      &#x27;StandardHours&#x27;, &#x27;MaritalStatus&#x27;,\n                                      &#x27;Gender&#x27;, &#x27;Age&#x27;])),\n                (&#x27;encoding&#x27;, encodingData()), (&#x27;clean&#x27;, cleanData()),\n                (&#x27;corr&#x27;, corrData())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;merge&#x27;,\n                 mergeDataFrame(employee_survey_data_df=      EmployeeID  EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance\n0              1                      3.0              4.0              2.0\n1              2                      3.0              2.0              4.0\n2              3                      2.0              2.0              1.0\n3              4                      4.0              4.0              3.0\n4              5                      4.0              1.0              3.0\n...          ...                      ...              ...              ...\n4405        4406                      4.0              1.0              3.0\n4406        4407                      4.0              4.0              3.0\n4407        4408                      1.0              3.0              3.0\n4408        4409                      4.0              1.0              3.0\n4409        4410                      1.0              3.0              NaN\n\n[4410 rows x 4 columns],\n                                in_time_df=      Unnamed: 0  2015-01-01           2015-01-02           2015-01-...\n3     2015-12-31 17:09:14  \n4     2015-12-31 17:42:14  \n...                   ...  \n4405  2015-12-31 18:30:41  \n4406  2015-12-31 16:18:39  \n4407  2015-12-31 18:08:55  \n4408  2015-12-31 19:33:45  \n4409  2015-12-31 16:39:18  \n\n[4410 rows x 262 columns])),\n                (&#x27;delete&#x27;,\n                 deleteColumns(array=[&#x27;EmployeeID&#x27;, &#x27;EmployeeCount&#x27;, &#x27;Over18&#x27;,\n                                      &#x27;StandardHours&#x27;, &#x27;MaritalStatus&#x27;,\n                                      &#x27;Gender&#x27;, &#x27;Age&#x27;])),\n                (&#x27;encoding&#x27;, encodingData()), (&#x27;clean&#x27;, cleanData()),\n                (&#x27;corr&#x27;, corrData())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">mergeDataFrame</label><div class=\"sk-toggleable__content\"><pre>mergeDataFrame(employee_survey_data_df=      EmployeeID  EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance\n0              1                      3.0              4.0              2.0\n1              2                      3.0              2.0              4.0\n2              3                      2.0              2.0              1.0\n3              4                      4.0              4.0              3.0\n4              5                      4.0              1.0              3.0\n...          ...                      ...              ...              ...\n4405        4406                      4.0              1.0              3.0\n4406        4407                      4.0              4.0              3.0\n4407        4408                      1.0              3.0              3.0\n4408        4409                      4.0              1.0              3.0\n4409        4410                      1.0              3.0              NaN\n\n[4410 rows x 4 columns],\n               in_time_df=      Unnamed: 0  2015-01-01           2015-01-02           2015-01-05  \\\n0              1         NaN  2015-01-02 09:43:4...\n4408  2015-12-28 19:58:36  2015-12-29 18:55:26  2015-12-30 19:37:22   \n4409  2015-12-28 17:14:44  2015-12-29 17:16:19  2015-12-30 17:29:55   \n\n               2015-12-31  \n0     2015-12-31 17:17:33  \n1     2015-12-31 17:40:58  \n2     2015-12-31 17:15:50  \n3     2015-12-31 17:09:14  \n4     2015-12-31 17:42:14  \n...                   ...  \n4405  2015-12-31 18:30:41  \n4406  2015-12-31 16:18:39  \n4407  2015-12-31 18:08:55  \n4408  2015-12-31 19:33:45  \n4409  2015-12-31 16:39:18  \n\n[4410 rows x 262 columns])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">deleteColumns</label><div class=\"sk-toggleable__content\"><pre>deleteColumns(array=[&#x27;EmployeeID&#x27;, &#x27;EmployeeCount&#x27;, &#x27;Over18&#x27;, &#x27;StandardHours&#x27;,\n                     &#x27;MaritalStatus&#x27;, &#x27;Gender&#x27;, &#x27;Age&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">encodingData</label><div class=\"sk-toggleable__content\"><pre>encodingData()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cleanData</label><div class=\"sk-toggleable__content\"><pre>cleanData()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">corrData</label><div class=\"sk-toggleable__content\"><pre>corrData()</pre></div></div></div></div></div></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('merge', mergeDataFrame(employee_survey_data_df, manager_survey_data_df, in_time_df, out_time_df)),\n",
    "    ('delete', deleteColumns(['EmployeeID', 'EmployeeCount', 'Over18', 'StandardHours', 'MaritalStatus', 'Gender', 'Age'])),\n",
    "    ('encoding', encodingData()),\n",
    "    ('clean', cleanData()),\n",
    "    ('corr', corrData())\n",
    "])\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "display(pipeline)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:00:31.938099800Z",
     "start_time": "2024-02-08T10:00:31.531458300Z"
    }
   },
   "id": "3f5df3156d7031c9",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      BusinessTravel  TotalWorkingYears  YearsAtCompany  YearsWithCurrManager  \\\n0                  1                1.0               1                     0   \n1                  2                6.0               5                     4   \n2                  2                5.0               5                     3   \n3                  0               13.0               8                     5   \n4                  1                9.0               6                     4   \n...              ...                ...             ...                   ...   \n4405               1               10.0               3                     2   \n4406               1               10.0               3                     2   \n4407               1                5.0               4                     2   \n4408               1               10.0               9                     8   \n4409               1               10.0              21                     9   \n\n      EnvironmentSatisfaction  JobSatisfaction  PresenceIndicator  \n0                         3.0              4.0                  0  \n1                         3.0              2.0                 42  \n2                         2.0              2.0                  0  \n3                         4.0              4.0                  0  \n4                         4.0              1.0                115  \n...                       ...              ...                ...  \n4405                      4.0              1.0                237  \n4406                      4.0              4.0                  0  \n4407                      1.0              3.0                 41  \n4408                      4.0              1.0                241  \n4409                      1.0              3.0                  0  \n\n[4410 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BusinessTravel</th>\n      <th>TotalWorkingYears</th>\n      <th>YearsAtCompany</th>\n      <th>YearsWithCurrManager</th>\n      <th>EnvironmentSatisfaction</th>\n      <th>JobSatisfaction</th>\n      <th>PresenceIndicator</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>6.0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5.0</td>\n      <td>5</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>13.0</td>\n      <td>8</td>\n      <td>5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>9.0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>115</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4405</th>\n      <td>1</td>\n      <td>10.0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>237</td>\n    </tr>\n    <tr>\n      <th>4406</th>\n      <td>1</td>\n      <td>10.0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4407</th>\n      <td>1</td>\n      <td>5.0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>4408</th>\n      <td>1</td>\n      <td>10.0</td>\n      <td>9</td>\n      <td>8</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>241</td>\n    </tr>\n    <tr>\n      <th>4409</th>\n      <td>1</td>\n      <td>10.0</td>\n      <td>21</td>\n      <td>9</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4410 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pipeline.fit_transform(general_data_df)\n",
    "\n",
    "labels = dataset.keys().to_list()\n",
    "labels.remove('Attrition')\n",
    "\n",
    "X = dataset[labels]\n",
    "y = dataset['Attrition']\n",
    "# Features\n",
    "X\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:00:34.531341600Z",
     "start_time": "2024-02-08T10:00:31.936961500Z"
    }
   },
   "id": "ab1fd5960b22a78e",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Choix des métriques de performance "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdf7eb2d87e66ee0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Afin de mesurer la performance de nos modèles pour savoir quels seront les meilleurs modèles, il est important de définir en amont des métriques de performance pour effectuer ce choix. Pour ce faire il existe plusieurs métriques de performance pour les problèmes de classification binaire."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6256a72631cd5a07"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Accuracy\n",
    "\n",
    "L'accuracy est la métrique la plus simple et la plus utilisée pour mesurer la performance d'un modèle. Elle représente le nombre de prédictions correctes (à la fois positives et négatives) par rapport au nombre total de prédictions. Cependant, cette métrique n'est pas toujours la meilleure pour mesurer la performance d'un modèle. En effet, dans le cas où les classes ne sont pas équilibrées, l'accuracy peut être trompeuse. Par exemple, si 90% des données appartiennent à la classe 1 et 10% à la classe 0, un modèle qui prédit toujours la classe 1 aura une accuracy de 90%.\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f113f2694cbf70b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Precision\n",
    "\n",
    "La precision est une métrique qui mesure la proportion de vrais positifs parmi les prédictions positives. Elle est utile lorsque le coût des faux positifs est élevé. Par exemple, dans le cas d'un modèle qui prédit si un email est un spam ou non, il est préférable d'avoir un faible taux de faux positifs (emails légitimes classés comme spam) même si cela signifie que certains spams seront classés comme légitimes.\n",
    "\n",
    "$$\n",
    "\\text{Précision} = \\frac{TP}{TP + FP}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7c69be06dcbb93e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recall \n",
    "\n",
    "Le recall (ou rappel) est une métrique qui mesure la proportion de vrais positifs parmi les vrais positifs et les faux négatifs. Elle est utile lorsque le coût des faux négatifs est élevé. Par exemple, dans le cas d'un modèle qui prédit si un patient a une maladie ou non, il est préférable d'avoir un faible taux de faux négatifs (patients malades classés comme sains) même si cela signifie que certains patients sains seront classés comme malades.\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "528cde6748234085"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## F1 Score\n",
    "\n",
    "Le F1 score est la moyenne harmonique de la precision et du recall. Il est utile lorsque les classes sont déséquilibrées. En effet, dans ce cas, l'accuracy n'est pas une bonne métrique de performance. Par exemple, si 90% des données appartiennent à la classe 1 et 10% à la classe 0, un modèle qui prédit toujours la classe 1 aura une accuracy de 90%. Cependant, le F1 score de ce modèle sera de 0. \n",
    "\n",
    "$$\n",
    "F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d93db0a4fa67b1f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AUC-ROC \n",
    "\n",
    "L'AUC-ROC (Area Under the Receiver Operating Characteristic Curve) est la mesure de la capacité d'un modèle à distinguer entre les classes. ROC est une courbe de probabilité qui trace le taux de vrais positifs contre le taux de faux positifs à différents seuils de classification. \n",
    "\n",
    "Un modèle qui fait des prédictions parfaites aurait une AUC de 1, tandis qu'un modèle qui fait des prédictions aléatoires aurait une AUC de 0.5.\n",
    "\n",
    "L'AUC-ROC est particulièrement utile lorsque les classes sont déséquilibrées. Elle est insensible au déséquilibre des classes et se concentre sur la capacité du modèle à distinguer entre les classes. Cependant, si le coût des faux positifs est très élevé, il peut être trompeur."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdd2e0fb997ffc2c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AUC PR\n",
    "\n",
    "L'AUC-PR est similaire à l'AUC-ROC mais se concentre sur la relation entre la précision (proportion de vrai positifs parmis les prédiction positives) et le recall (proportion de vrais positifs parmis les vrais cas positifs). \n",
    "\n",
    "Dans un contexte où les positifs (comme les spams dans un exemple de filtrage) sont rares, l'AUC-PR donne une meilleure indication de la performance du modèle. \n",
    "\n",
    "L'AUC-PR est préférable lorsque le déséquilibre des classe est un problème et que l'on s'intéresse davantage à la performance du modèle sur la classe minoritaire. Il est plus informatif que l'AUC-ROC dans les cas où les positifs sont beaucoup moins fréquents que les négatifs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5f68b174414e205"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Choix appliqué au contexte "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7982437808d226a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pour le problème de l'attrition des employés, qui est un problème de classification binaire (les employés quittent ou ne quittent pas l'entreprise) \n",
    "\n",
    "Il est important de prendre en compte le coût relatif des erreurs (faux positifs vs faux négatifs) et la distribution de la classe (équilibrée ou déséquilibrée).\n",
    "\n",
    "* Si le *coût d'un faux négatif* (ne pas identifier un employé qui est susceptible de quitter) est élevée car cela pourrait perturber les opérations de l'entreprise, entaîner la perte de talent clés ou nuire à la plannification des ressources, alors il est préférable de privilégier *le recall*.\n",
    "\n",
    "* Si le coût d'un faux positif (croire à tort qu'un employé va partir) est élevée, ce qui conduit à un problème éthique et conduire à des dépenses inutiles en interventions de rétention ou à une ambiance de méfiance, alors il est préférable de privilégier la précision. \n",
    "\n",
    "Dans le contexte de notre problème, ces deux types d'erreurs sont importants, le F1-Score peut être un bon choix car il équilibre la précision et le recall. Cependant nos données étant déséquilibrées, les mesures telles que la précision, le recall et le F1-Score peuvent ne pas refléter fidèlement la performance de notre modèle.\n",
    "\n",
    "Dans ce cas L'AUC-ROC ou l'AUC-PR pourraient être plus appropriées. L'AUC-ROC est moins sensible aux déséquilibres de classe, mais si la classe positive (les employés qui quittent est beaucoup plus petite, l'AUC-PR peut être préférable car elle se concentre sur la classe minoritaire. \n",
    "\n",
    "Les autres métriques sont évidemment utiles pour évaluer la performance des modèles, mais prendrons en priorité l'AUC-PR et le F1-Score pour évaluer la performance de nos modèles."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f834eb0afb473d4e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Choix du modèle "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a414e98f27dc9f21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Afin de choisir le modèle le plus adapté à notre problème de classification, nous allons comparer les performances de plusieurs modèles de classification. Pour réaliser cela, nous allons utiliser la bibliothèque pycaret qui permet de comparer les performances de plusieurs modèles de classification. Cette bibliothèque va lancer un processus d'entraînement et de test sur plusieurs modèles de classification et nous donnera les performances de chacun de ces modèles."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c95f2395a70b26d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "La métrique de l'AUC-PR n'étant pas nativement disponible dans la bibliothèque pycaret. Toutefois il est possible de créer une métrique personnalisée pour l'AUC-PR. \n",
    "\n",
    "Pour cela, nous allons utiliser "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1130a563788b3a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def auc_pr_score(y_true, y_scores):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "    return auc(recall, precision)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:00:34.532341400Z",
     "start_time": "2024-02-08T10:00:34.528193900Z"
    }
   },
   "id": "b3072cd01fc42163",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                                                    \n                                                                    \nInitiated  . . . . . . . . . . . . . . . . . .              11:00:34\nStatus     . . . . . . . . . . . . . . . . . .  Loading Dependencies\nEstimator  . . . . . . . . . . . . . . . . . .     Compiling Library",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Initiated</th>\n      <td>. . . . . . . . . . . . . . . . . .</td>\n      <td>11:00:34</td>\n    </tr>\n    <tr>\n      <th>Status</th>\n      <td>. . . . . . . . . . . . . . . . . .</td>\n      <td>Loading Dependencies</td>\n    </tr>\n    <tr>\n      <th>Estimator</th>\n      <td>. . . . . . . . . . . . . . . . . .</td>\n      <td>Compiling Library</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Processing:   0%|          | 0/61 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "271bec694cb144e9922aefab7e520787"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                    Model  Accuracy     AUC  Recall   Prec.  \\\net                 Extra Trees Classifier    0.9657  0.9705  0.8436  0.9381   \nrf               Random Forest Classifier    0.9521  0.9630  0.7692  0.9225   \ndt               Decision Tree Classifier    0.9219  0.8691  0.7552  0.7640   \nlightgbm  Light Gradient Boosting Machine    0.9067  0.9364  0.5240  0.8402   \ndummy                    Dummy Classifier    0.8387  0.5000  0.0000  0.0000   \ngbc          Gradient Boosting Classifier    0.8698  0.8385  0.3113  0.7323   \nada                  Ada Boost Classifier    0.8623  0.8085  0.2692  0.6880   \nnb                            Naive Bayes    0.8549  0.7575  0.2891  0.6118   \nqda       Quadratic Discriminant Analysis    0.8510  0.7527  0.2951  0.5796   \nlr                    Logistic Regression    0.8523  0.7692  0.1706  0.6526   \nridge                    Ridge Classifier    0.8416  0.0000  0.0261  0.6500   \nknn                K Neighbors Classifier    0.8380  0.7991  0.2871  0.5087   \nlda          Linear Discriminant Analysis    0.8468  0.7684  0.1526  0.5968   \nsvm                   SVM - Linear Kernel    0.7911  0.0000  0.2003  0.2746   \n\n              F1   Kappa     MCC  AUC-PR  TT (Sec)  \net        0.8876  0.8675  0.8696  0.9035     0.033  \nrf        0.8377  0.8099  0.8152  0.8645     0.042  \ndt        0.7573  0.7109  0.7124  0.7793     0.005  \nlightgbm  0.6419  0.5920  0.6155  0.7205     0.138  \ndummy     0.0000  0.0000  0.0000  0.5807     0.005  \ngbc       0.4328  0.3730  0.4185  0.5774     0.033  \nada       0.3814  0.3219  0.3690  0.5375     0.018  \nnb        0.3892  0.3192  0.3496  0.5078     0.005  \nqda       0.3879  0.3137  0.3382  0.4942     0.005  \nlr        0.2674  0.2173  0.2788  0.4785     0.384  \nridge     0.0500  0.0400  0.1106  0.4666     0.004  \nknn       0.3637  0.2791  0.2959  0.4554     0.281  \nlda       0.2409  0.1886  0.2441  0.4430     0.004  \nsvm       0.1822  0.0953  0.1111  0.3019     0.005  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>AUC-PR</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>et</th>\n      <td>Extra Trees Classifier</td>\n      <td>0.9657</td>\n      <td>0.9705</td>\n      <td>0.8436</td>\n      <td>0.9381</td>\n      <td>0.8876</td>\n      <td>0.8675</td>\n      <td>0.8696</td>\n      <td>0.9035</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>Random Forest Classifier</td>\n      <td>0.9521</td>\n      <td>0.9630</td>\n      <td>0.7692</td>\n      <td>0.9225</td>\n      <td>0.8377</td>\n      <td>0.8099</td>\n      <td>0.8152</td>\n      <td>0.8645</td>\n      <td>0.042</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.9219</td>\n      <td>0.8691</td>\n      <td>0.7552</td>\n      <td>0.7640</td>\n      <td>0.7573</td>\n      <td>0.7109</td>\n      <td>0.7124</td>\n      <td>0.7793</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>lightgbm</th>\n      <td>Light Gradient Boosting Machine</td>\n      <td>0.9067</td>\n      <td>0.9364</td>\n      <td>0.5240</td>\n      <td>0.8402</td>\n      <td>0.6419</td>\n      <td>0.5920</td>\n      <td>0.6155</td>\n      <td>0.7205</td>\n      <td>0.138</td>\n    </tr>\n    <tr>\n      <th>dummy</th>\n      <td>Dummy Classifier</td>\n      <td>0.8387</td>\n      <td>0.5000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.5807</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>gbc</th>\n      <td>Gradient Boosting Classifier</td>\n      <td>0.8698</td>\n      <td>0.8385</td>\n      <td>0.3113</td>\n      <td>0.7323</td>\n      <td>0.4328</td>\n      <td>0.3730</td>\n      <td>0.4185</td>\n      <td>0.5774</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>ada</th>\n      <td>Ada Boost Classifier</td>\n      <td>0.8623</td>\n      <td>0.8085</td>\n      <td>0.2692</td>\n      <td>0.6880</td>\n      <td>0.3814</td>\n      <td>0.3219</td>\n      <td>0.3690</td>\n      <td>0.5375</td>\n      <td>0.018</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.8549</td>\n      <td>0.7575</td>\n      <td>0.2891</td>\n      <td>0.6118</td>\n      <td>0.3892</td>\n      <td>0.3192</td>\n      <td>0.3496</td>\n      <td>0.5078</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>qda</th>\n      <td>Quadratic Discriminant Analysis</td>\n      <td>0.8510</td>\n      <td>0.7527</td>\n      <td>0.2951</td>\n      <td>0.5796</td>\n      <td>0.3879</td>\n      <td>0.3137</td>\n      <td>0.3382</td>\n      <td>0.4942</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.8523</td>\n      <td>0.7692</td>\n      <td>0.1706</td>\n      <td>0.6526</td>\n      <td>0.2674</td>\n      <td>0.2173</td>\n      <td>0.2788</td>\n      <td>0.4785</td>\n      <td>0.384</td>\n    </tr>\n    <tr>\n      <th>ridge</th>\n      <td>Ridge Classifier</td>\n      <td>0.8416</td>\n      <td>0.0000</td>\n      <td>0.0261</td>\n      <td>0.6500</td>\n      <td>0.0500</td>\n      <td>0.0400</td>\n      <td>0.1106</td>\n      <td>0.4666</td>\n      <td>0.004</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.8380</td>\n      <td>0.7991</td>\n      <td>0.2871</td>\n      <td>0.5087</td>\n      <td>0.3637</td>\n      <td>0.2791</td>\n      <td>0.2959</td>\n      <td>0.4554</td>\n      <td>0.281</td>\n    </tr>\n    <tr>\n      <th>lda</th>\n      <td>Linear Discriminant Analysis</td>\n      <td>0.8468</td>\n      <td>0.7684</td>\n      <td>0.1526</td>\n      <td>0.5968</td>\n      <td>0.2409</td>\n      <td>0.1886</td>\n      <td>0.2441</td>\n      <td>0.4430</td>\n      <td>0.004</td>\n    </tr>\n    <tr>\n      <th>svm</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.7911</td>\n      <td>0.0000</td>\n      <td>0.2003</td>\n      <td>0.2746</td>\n      <td>0.1822</td>\n      <td>0.0953</td>\n      <td>0.1111</td>\n      <td>0.3019</td>\n      <td>0.005</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = setup(data=dataset, target='Attrition')\n",
    "add_metric('AUC-PR', 'AUC-PR', auc_pr_score, greater_is_better=True)\n",
    "best__models = compare_models(sort='AUC-PR')\n",
    "\n",
    "results = pull()\n",
    "\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:00:46.061361500Z",
     "start_time": "2024-02-08T10:00:34.531341600Z"
    }
   },
   "id": "ad8b5d39d30cef3a",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def optimize_model(model):\n",
    "    return tune_model(model, optimize='AUC-PR')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:39:09.931419300Z",
     "start_time": "2024-02-08T10:39:09.920905200Z"
    }
   },
   "id": "c791a18c102640ea",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1115\n",
      "           1       0.95      0.85      0.89       208\n",
      "\n",
      "    accuracy                           0.97      1323\n",
      "   macro avg       0.96      0.92      0.94      1323\n",
      "weighted avg       0.97      0.97      0.97      1323\n",
      "\n",
      "[[1105   10]\n",
      " [  32  176]]\n",
      "0.9682539682539683\n",
      "0.8248491566463917\n",
      "0.9082889290262562\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classifier with sci-kit learn\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, average_precision_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(average_precision_score(y_test, y_pred))\n",
    "\n",
    "# Print auc-pr score\n",
    "print(auc_pr_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:39:10.954075500Z",
     "start_time": "2024-02-08T10:39:10.789924400Z"
    }
   },
   "id": "43c7a7e71f56fff6",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                    \n                                                                    \nInitiated  . . . . . . . . . . . . . . . . . .              11:39:32\nStatus     . . . . . . . . . . . . . . . . . .  Loading Dependencies\nEstimator  . . . . . . . . . . . . . . . . . .     Compiling Library",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Initiated</th>\n      <td>. . . . . . . . . . . . . . . . . .</td>\n      <td>11:39:32</td>\n    </tr>\n    <tr>\n      <th>Status</th>\n      <td>. . . . . . . . . . . . . . . . . .</td>\n      <td>Loading Dependencies</td>\n    </tr>\n    <tr>\n      <th>Estimator</th>\n      <td>. . . . . . . . . . . . . . . . . .</td>\n      <td>Compiling Library</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Processing:   0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "448879393bc6460a9852eda4aa29b8fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Accuracy  AUC  Recall   Prec.      F1  Kappa  MCC  AUC-PR\nFold                                                           \n0       0.1618  0.5     1.0  0.1618  0.2786    0.0  0.0  0.5809\n1       0.1618  0.5     1.0  0.1618  0.2786    0.0  0.0  0.5809\n2       0.1618  0.5     1.0  0.1618  0.2786    0.0  0.0  0.5809\n3       0.1618  0.5     1.0  0.1618  0.2786    0.0  0.0  0.5809\n4       0.1618  0.5     1.0  0.1618  0.2786    0.0  0.0  0.5809\n5       0.1618  0.5     1.0  0.1618  0.2786    0.0  0.0  0.5809\n6       0.1618  0.5     1.0  0.1618  0.2786    0.0  0.0  0.5809\n7       0.1623  0.5     1.0  0.1623  0.2793    0.0  0.0  0.5812\n8       0.1591  0.5     1.0  0.1591  0.2745    0.0  0.0  0.5795\n9       0.1591  0.5     1.0  0.1591  0.2745    0.0  0.0  0.5795\nMean    0.1613  0.5     1.0  0.1613  0.2778    0.0  0.0  0.5807\nStd     0.0011  0.0     0.0  0.0011  0.0017    0.0  0.0  0.0006",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>AUC-PR</th>\n    </tr>\n    <tr>\n      <th>Fold</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.1618</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.1618</td>\n      <td>0.2786</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5809</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.1618</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.1618</td>\n      <td>0.2786</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5809</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.1618</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.1618</td>\n      <td>0.2786</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5809</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.1618</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.1618</td>\n      <td>0.2786</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5809</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.1618</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.1618</td>\n      <td>0.2786</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5809</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.1618</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.1618</td>\n      <td>0.2786</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5809</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.1618</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.1618</td>\n      <td>0.2786</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5809</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.1623</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.1623</td>\n      <td>0.2793</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5812</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.1591</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.1591</td>\n      <td>0.2745</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5795</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.1591</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.1591</td>\n      <td>0.2745</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5795</td>\n    </tr>\n    <tr>\n      <th>Mean</th>\n      <td>0.1613</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.1613</td>\n      <td>0.2778</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5807</td>\n    </tr>\n    <tr>\n      <th>Std</th>\n      <td>0.0011</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0011</td>\n      <td>0.0017</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0006</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def optimize_with_grid_search_cv(model, param_grid):\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=auc_pr_scorer, cv=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_params_, grid_search.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:39:35.640296400Z",
     "start_time": "2024-02-08T10:39:32.671684400Z"
    }
   },
   "id": "c46285153919b889",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'bootstrap': False,\n 'max_depth': 20,\n 'max_features': 'log2',\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'n_estimators': 50}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, average_precision_score\n",
    "auc_pr_scorer = make_scorer(auc_pr_score , needs_proba=True)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=auc_pr_scorer, cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:03:23.990674900Z",
     "start_time": "2024-02-08T10:00:46.246088600Z"
    }
   },
   "id": "d13b045077bedabf",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.9014246049937386"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:03:24.015488400Z",
     "start_time": "2024-02-08T10:03:23.990674900Z"
    }
   },
   "id": "76c83b19ba36f6fb",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1115\n",
      "           1       0.92      0.75      0.83       208\n",
      "\n",
      "    accuracy                           0.95      1323\n",
      "   macro avg       0.94      0.87      0.90      1323\n",
      "weighted avg       0.95      0.95      0.95      1323\n",
      "\n",
      "[[1101   14]\n",
      " [  51  157]]\n",
      "0.9508692365835223\n",
      "0.7315593241345121\n",
      "0.8557425500564598\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with sci-kit learn\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, average_precision_score\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(average_precision_score(y_test, y_pred))\n",
    "print(auc_pr_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:03:24.363258700Z",
     "start_time": "2024-02-08T10:03:24.000152400Z"
    }
   },
   "id": "66edc97476eccc6b",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'bootstrap': False,\n 'max_depth': 80,\n 'max_features': 'auto',\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'n_estimators': 200}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=auc_pr_scorer, cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:06:40.890861500Z",
     "start_time": "2024-02-08T10:03:24.350308100Z"
    }
   },
   "id": "50bef99dfe5d9bef",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.8840096620134421"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T10:06:40.900995700Z",
     "start_time": "2024-02-08T10:06:40.891433400Z"
    }
   },
   "id": "c55d63f48659ef4a",
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
